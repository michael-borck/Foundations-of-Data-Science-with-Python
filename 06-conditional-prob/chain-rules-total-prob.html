
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6.9. Chain Rules and Total Probability &#8212; Foundations of Data Science with Python</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6.10. Review" href="review.html" />
    <link rel="prev" title="6.8. Conditioning and (In)dependence" href="conditional-independence.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Foundations of Data Science with Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Foundations of Data Science with Python
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01-intro/intro.html">
   1. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/who-for.html">
     1.1. Who is this book for?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/why-this-book.html">
     1.2. Why learn data science from this book?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/what-is-data-science.html">
     1.3. What is data science?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/what-book-covers.html">
     1.4. What data science topics does this book cover?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/intro-jupyter-and-python.html">
     1.5. Extremely Brief Intro to Jupyter and Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/jupyter-start.html">
     1.6. Getting Started in Jupyter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/python-start.html">
     1.7. Getting Started in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/review.html">
     1.8. Review
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02-first-stats/intro.html">
   2. First Simulations, Visualizations, and Statistical Tests
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-first-stats/motivating-problem.html">
     2.1. Motivating Problem: Is This Coin Fair?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-first-stats/first-sims.html">
     2.2. First Computer Simulations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-first-stats/first-vis.html">
     2.3. First Visualizations: Scatter Plots and Histograms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-first-stats/first-stats.html">
     2.4. First Statistical Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-first-stats/review.html">
     2.5. Review
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03-first-data/intro.html">
   3. First Visualizations and Statistical Tests with Real Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-first-data/pandas-start.html">
     3.1. Intro to Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-first-data/visualization.html">
     3.2. Visualizing Multiple Data Sets - Part 1: Scatter Plots
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-first-data/partitions.html">
     3.3. Partitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-first-data/summary-stats.html">
     3.4. Summary Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-first-data/histogram.html">
     3.5. Visualizing Multiple Data Sets - Part 2: Histograms for Partitioned Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-first-data/hypothesis-testing.html">
     3.6. Binary Hypothesis Testing with Real Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-first-data/2d-scatter.html">
     3.7. A Quick Preview of Two-Dimensional Statistical Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-first-data/review.html">
     3.8. Review
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04-probability1/intro.html">
   4. Introduction to Probability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-probability1/outcomes-samplespaces-events.html">
     4.1. Outcomes, Sample Spaces, and Events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-probability1/relative-frequency.html">
     4.2. Relative Frequencies and Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-probability1/fair-experiments.html">
     4.3. Fair Experiments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-probability1/axiomatic-prob.html">
     4.4. Axiomatic  Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-probability1/corollaries.html">
     4.5. Corollaries to the Axioms of Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-probability1/combinatorics.html">
     4.6. Combinatorics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-probability1/review.html">
     4.7. Review
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-probability1/summary.html">
     4.8. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05-binary-hypothesis-testing/outline.html">
   5. Binary Hypothesis Tests with Resampling (Outline)
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   6. Dependence and Independence
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="simulating-cond-probs.html">
     6.1. Simulating and Counting Conditional Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="notation-and-intuition.html">
     6.2. Conditional Probability: Notation and Intuition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="definition.html">
     6.3. Formally Defining Conditional Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="relating-cond-uncond.html">
     6.4. Relating Conditional and Unconditional Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="more-on-simulating.html">
     6.5. More on Simulating Conditional Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="independence.html">
     6.6. Statistical Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fair-exps.html">
     6.7. Conditional Probabilities and Independence in Fair Experiments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="conditional-independence.html">
     6.8. Conditioning and (In)dependence
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     6.9. Chain Rules and Total Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="review.html">
     6.10. Review
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="summary.html">
     6.11. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07-bayesian-methods/intro.html">
   7. Introduction to Bayesian Methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-bayesian-methods/bayes-rule.html">
     7.1. Bayes’ Rule
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-bayesian-methods/bayes-hidden-state.html">
     7.2. Bayes’ Rule in Systems with Hidden State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-bayesian-methods/optimal-decisions.html">
     7.3. Optimal Decisions for Discrete Stochastic Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-bayesian-methods/bayesian-hypothesis-testing.html">
     7.4. Bayesian Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-bayesian-methods/review.html">
     7.5. Review
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-bayesian-methods/summary.html">
     7.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08-random-variables/intro.html">
   8. Random Variables (In Progress)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-random-variables/definition.html">
     8.1. Definition of a Real Random Variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-random-variables/discrete-rvs.html">
     8.2. Discrete Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-random-variables/cdfs.html">
     8.3. Cumulative Distribution Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-random-variables/outline.html">
     8.4. Common Discrete Random Variables and Their Applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-moments/outline.html">
   9. Moments, Parameter Estimation, and Binary Hypothesis Tests on Sample Means (Outline)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10-conditional-stats/outline.html">
   10. Applications of Conditional Distributions to Statistical Tests (Outline)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../11-matrix-vector-regression/outline.html">
   11. Multidimensional Data and Regression (Outline)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../12-categorical-data/outline.html">
   12. Tests of Independence for Categorical Data (Outline)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../13-clustering-transforming/outline.html">
   13. Clustering and Transforming Multi-dimensional Data (Outline)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../14-matrix-applications/outline.html">
   14. Applications of Matrices to Solving Equations, Curve Fitting, and Regression (Outline)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../15-multidim-dependence/outline.html">
   15. Working with Dependent Data in Multiple Dimensions (Outline)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../16-next-steps/outline.html">
   16. Next Steps (Outline)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../genindex.html">
   17. Index
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/06-conditional-prob/chain-rules-total-prob.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/06-conditional-prob/chain-rules-total-prob.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-conditional-probability-to-decompose-events-part-1-chain-rules">
   6.9.1. Using Conditional Probability to Decompose Events: Part 1 – Chain Rules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-conditional-probability-to-decompose-events-part-2-partitions-and-total-probability">
   6.9.2. Using Conditional Probability to Decompose Events: Part 2 –  Partitions, and Total Probability
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Chain Rules and Total Probability</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-conditional-probability-to-decompose-events-part-1-chain-rules">
   6.9.1. Using Conditional Probability to Decompose Events: Part 1 – Chain Rules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-conditional-probability-to-decompose-events-part-2-partitions-and-total-probability">
   6.9.2. Using Conditional Probability to Decompose Events: Part 2 –  Partitions, and Total Probability
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="chain-rules-and-total-probability">
<h1><span class="section-number">6.9. </span>Chain Rules and Total Probability<a class="headerlink" href="#chain-rules-and-total-probability" title="Permalink to this headline">¶</a></h1>
<p>In this section, we introduce techniques that use conditional probability to decompose events. The goal is to express unknown probabilities of events in terms of probabilities that we already know.</p>
<div class="section" id="using-conditional-probability-to-decompose-events-part-1-chain-rules">
<h2><span class="section-number">6.9.1. </span>Using Conditional Probability to Decompose Events: Part 1 – Chain Rules<a class="headerlink" href="#using-conditional-probability-to-decompose-events-part-1-chain-rules" title="Permalink to this headline">¶</a></h2>
<p>From the definition of conditional probability, we can write <span class="math notranslate nohighlight">\(P(A|B)\)</span> as</p>
<div class="amsmath math notranslate nohighlight" id="equation-6b8e5a56-b368-4235-a5cb-e2f06c0b0488">
<span class="eqno">(6.10)<a class="headerlink" href="#equation-6b8e5a56-b368-4235-a5cb-e2f06c0b0488" title="Permalink to this equation">¶</a></span>\[\begin{align}
  P(A|B)&amp;= \frac{P(A \cap B)}{P(B)}  \\
  \Rightarrow P(A \cap B)&amp;= P(A|B)P(B), 
\end{align}\]</div>
<p>and we can write <span class="math notranslate nohighlight">\(P(B|A)\)</span> as</p>
<div class="amsmath math notranslate nohighlight" id="equation-f4fd9eaa-5c7a-4ba9-b8ae-c52ab9b31d32">
<span class="eqno">(6.11)<a class="headerlink" href="#equation-f4fd9eaa-5c7a-4ba9-b8ae-c52ab9b31d32" title="Permalink to this equation">¶</a></span>\[\begin{align}
  P(B|A)&amp;=\frac{P(A \cap B)}{P(A)}  \\
  \Rightarrow P(A \cap B)&amp;= P(B|A)P(A).
\end{align}\]</div>
<p>After manipulating the expressions as shown, we get two <em>different</em> formula for expressing <span class="math notranslate nohighlight">\(P(A \cap B)\)</span>. These are <strong>chain rules</strong> for the probability of the intersection of two events. Such rules are often used when:</p>
<ul class="simple">
<li><p>Two events are dependent on each other, but the relation is simple if the outcome of one of the experiments is known.</p></li>
<li><p>The events are at two different point in a system, such as the input and output of a system.</p></li>
</ul>
<p><strong>Example</strong></p>
<p>A simple example of the former is in card games. Two cards are drawn (without replacement) from a deck of 52 cards (without jokers). What is the probability that they are both Aces? Let <span class="math notranslate nohighlight">\(A_i\)</span> be the event that the card on draw <span class="math notranslate nohighlight">\(i\)</span> is an Ace. Then the most natural way to apply the chain rule is to write</p>
<div class="math notranslate nohighlight">
\[
P(A_1 \cap A_2) = P(A_2 | A_1) P(A_1).
\]</div>
<p>The probability of getting an Ace in draw 1 is 4/52=1/13 because there are 4 Aces in the deck of 52 cards.  The probability of getting an Ace on the second draw <em>given that the first draw was an Ace</em> is 3/51 = 1/17 because after the first draw, there are 3 Aces left in the remaining deck of 51 cards.  Thus,</p>
<div class="math notranslate nohighlight">
\[
P(A_1 \cap A_2) = P(A_2 | A_1) P(A_1) = \left( \frac{1}{17} \right) \left( \frac{1}{13} \right) = \frac{1}{221}
\]</div>
<p>As a check, we can compare with a solution using combinatorics. There are</p>
<div class="math notranslate nohighlight">
\[
\binom{4}{2} = 6
\]</div>
<p>ways to choose the two Aces from the four total Aces. There are</p>
<div class="math notranslate nohighlight">
\[
\binom{52}{2} = \frac{ 52!}{50! 2!} = 1326
\]</div>
<p>ways to choose two cards from 52. So,</p>
<div class="math notranslate nohighlight">
\[
P( A_1 \cap A_2) = \frac{6}{1326} = \frac{1}{221},
\]</div>
<p>which matches our answer using conditional probability.</p>
<p>The solution using conditional probability is usually much more intuitive for learners who are new to probability, but being able to use both techniques is a powerful method for checking your work</p>
<p><strong>To be added: Question on probability of getting two face cards (JQK) on consecutive draws from a deck of cards. Question on getting defective computers when sitting down at random computers in a lab.</strong></p>
<p><strong>Example</strong></p>
<p>For the Magician’s Coin problem, what is the probability of getting the Fair coin and it coming up heads on the first flip? This is an example of a system where there is an input that affects the future outputs. In this case, the input is the choice of coin. When we have such problems, we usually will need to decompose them in terms of the probabilities of the input and the conditional probabilities of the output given the input. Let <span class="math notranslate nohighlight">\(H_i\)</span> denote the event that the coin comes up heads on flip <span class="math notranslate nohighlight">\(i\)</span>. Let <span class="math notranslate nohighlight">\(F\)</span> be the event that the fair coin was chosen.  We are looking for <span class="math notranslate nohighlight">\(P(F \cap H_1)\)</span>, which we can write as</p>
<div class="math notranslate nohighlight">
\[
P(F \cap H_1) = P(H_1 | F) P(F).
\]</div>
<p>If there is one Fair coin and one two-headed coin, <span class="math notranslate nohighlight">\(P(F) =1/2\)</span>.  Given  that the coin is Fair, <span class="math notranslate nohighlight">\(P(H_1|F) = 1/2\)</span>. So,</p>
<div class="math notranslate nohighlight">
\[
P(F \cap H_1) = \left( \frac 1 2  \right) \left( \frac 1 2  \right) = \frac 1 4.
\]</div>
<p>Note that it is generally <strong>not helpful to write the probability using the other form of the chain rule:</strong></p>
<div class="math notranslate nohighlight">
\[
P(F \cap H_1) = P(F| H_1) P(H_1).
\]</div>
<p>We do not know <span class="math notranslate nohighlight">\(P(H_1)\)</span> nor <span class="math notranslate nohighlight">\(P(F|H_1)\)</span>. Thus, although the expression is valid mathematically, it is not helpful in solving this problem because it depends on probabilities that cannot be easily inferred from the problem setup.</p>
<p><strong>To be added:Question on probability  of getting the Fair coin and heads on first two flips.</strong></p>
<p>The chain rule can be easily generalized to more than two events. The easiest way is to write probabilities in terms of conditional probabilities that are expressed as fractions (as in the definition of probability), such that the denumenator of one fraction cancels with the numerator of the next fraction to make sure the expression is not changes when it is rewritten. This will make more sense with an example for rewriting the probability of the intersection of 3 events (<span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span>, and <span class="math notranslate nohighlight">\(C\)</span>):</p>
<div class="amsmath math notranslate nohighlight" id="equation-c5baefda-c115-46eb-b284-62939e6891d3">
<span class="eqno">(6.12)<a class="headerlink" href="#equation-c5baefda-c115-46eb-b284-62939e6891d3" title="Permalink to this equation">¶</a></span>\[\begin{align}
  P(A \cap B \cap C) &amp;= \frac{P(A \cap B \cap C)} {}  \cdot
  \frac{\hspace{4em} }{} \cdot \frac{ \hspace{3em}\mbox{    }}{} \\
  &amp;\\
  &amp;= \frac{P(A \cap B \cap C)} {P(B \cap C)}  \cdot
  \frac{P(B \cap C)}{\mbox{   }} \cdot \frac{ \hspace{3em}\mbox{    }}{} \\
    &amp;= \frac{P(A \cap B \cap C)} {P(B \cap C)}  \cdot
  \frac{P(B \cap C)}{P(C)} \cdot \frac{ P(C) }{1} \\
  &amp;= P(A|B \cap C)  P(B | C) P(C)
\end{align}\]</div>
<p>This decomposition assumes we know the probability of  <span class="math notranslate nohighlight">\(A\)</span> given that <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(C\)</span> have occurred and we know the probability of <span class="math notranslate nohighlight">\(B\)</span> given <span class="math notranslate nohighlight">\(C\)</span>. Such dependence occurs naturally in many systems, but the particular decomposition will depend on what we know about these probabilities. We could just have easily written</p>
<div class="amsmath math notranslate nohighlight" id="equation-bd317a8e-8dc2-4608-83af-0cb7a256026b">
<span class="eqno">(6.13)<a class="headerlink" href="#equation-bd317a8e-8dc2-4608-83af-0cb7a256026b" title="Permalink to this equation">¶</a></span>\[\begin{align}
  P(A \cap B \cap C) 
  &amp;= P(C|A \cap B)  P(B | A) P(A)
\end{align}\]</div>
</div>
<div class="section" id="using-conditional-probability-to-decompose-events-part-2-partitions-and-total-probability">
<h2><span class="section-number">6.9.2. </span>Using Conditional Probability to Decompose Events: Part 2 –  Partitions, and Total Probability<a class="headerlink" href="#using-conditional-probability-to-decompose-events-part-2-partitions-and-total-probability" title="Permalink to this headline">¶</a></h2>
<p>We previously introduced the concept of partitions in <a class="reference internal" href="../03-first-data/partitions.html"><span class="doc">Partitions</span></a> as a way to take a collection of data and break it into separate, disjoint groups. Now, we are ready to apply this concept to events, which are sets of outcomes. In particular, we will most often partition the sample space, <span class="math notranslate nohighlight">\(S\)</span>:</p>
<div class="sphinx-bs container pb-4 docutils">
<div class="row docutils">
<div class="d-flex col-lg-6 col-md-6 col-sm-6 col-xs-12 p-2 docutils">
<div class="card w-100 shadow docutils">
<div class="card-header docutils">
<p class="card-text">DEFINITION</p>
</div>
<div class="card-body docutils">
<dl class="simple myst">
<dt>partition (of the sample space)</dt><dd><p class="card-text">A collection of sets <span class="math notranslate nohighlight">\(A_1, A_2, \ldots\)</span> <em>partitions</em>
the sample space <span class="math notranslate nohighlight">\(S\)</span> iff</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
  S &amp;= \bigcup_i A_i,     \mbox{ and } 
  A_i \cap A_j &amp;= \emptyset, i \ne j. 
  \end{align*}\]</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\left\{A_i \right\}\)</span> is also said to be a <em>partition</em> of <span class="math notranslate nohighlight">\(S\)</span>. For example, the collection of disjoint sets <span class="math notranslate nohighlight">\(A_0 A_1, \ldots, A_7\)</span> shown in <a class="reference internal" href="#sample-space-partition"><span class="std std-numref">Fig. 6.3</span></a> is a partition for <span class="math notranslate nohighlight">\(S\)</span>:</p>
<div class="figure align-default" id="sample-space-partition">
<a class="reference internal image-reference" href="../_images/sample-space-partition.png"><img alt="$A_0, A_1, \ldots, A_7$ are disjoint sets whose union is $S$." src="../_images/sample-space-partition.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 6.3 </span><span class="caption-text">Example partition of the sample space.</span><a class="headerlink" href="#sample-space-partition" title="Permalink to this image">¶</a></p>
</div>
<p>Now consider how we can use a partition <span class="math notranslate nohighlight">\(A_0, A_1, \ldots, A_{n-1}\)</span> of <span class="math notranslate nohighlight">\(S\)</span> to decompose any event <span class="math notranslate nohighlight">\(B \subseteq S\)</span>. In <a class="reference internal" href="#event-partition1"><span class="std std-numref">Fig. 6.4</span></a>, an example event <span class="math notranslate nohighlight">\(B\)</span> is shown on top of our example partition. Note that we do not require the <span class="math notranslate nohighlight">\(B\)</span> have a nonempty intersection with every partition event (i.e., in this example <span class="math notranslate nohighlight">\(B \cap A_0 = \emptyset\)</span>).</p>
<div class="figure align-default" id="event-partition1">
<a class="reference internal image-reference" href="../_images/event-partition1.png"><img alt="Figure showing an event $B$ on top of a partition of the sample space, $A_0, A_1, \ldots, A_7$." src="../_images/event-partition1.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 6.4 </span><span class="caption-text">Example event <span class="math notranslate nohighlight">\(B\)</span> superimposed on partition <span class="math notranslate nohighlight">\(A_0, A_1, \ldots, A_7\)</span> of the sample space.</span><a class="headerlink" href="#event-partition1" title="Permalink to this image">¶</a></p>
</div>
<p>Then we can use our partition to decompose <span class="math notranslate nohighlight">\(B\)</span> into smaller subsets as</p>
<div class="math notranslate nohighlight">
\[
B_i = B \cap A_i, ~~ i = 0, 1, \ldots, n-1,
\]</div>
<p>as shown in <a class="reference internal" href="#event-partition2"><span class="std std-numref">Fig. 6.5</span></a>.</p>
<div class="figure align-default" id="event-partition2">
<a class="reference internal image-reference" href="../_images/event-partition2.png"><img alt="Figure showing an event $B$ partitioned into subsets $B_0, B_1, \ldots B_7$ through intersection with $A_0, A_1, \ldots, A_7$." src="../_images/event-partition2.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 6.5 </span><span class="caption-text">Example event <span class="math notranslate nohighlight">\(B\)</span> superimposed on partition <span class="math notranslate nohighlight">\(A_0, A_1, \ldots, A_7\)</span> of the sample space.</span><a class="headerlink" href="#event-partition2" title="Permalink to this image">¶</a></p>
</div>
<p>Note that <span class="math notranslate nohighlight">\(A_i \cap A_j = \emptyset\)</span> also implies that</p>
<div class="math notranslate nohighlight">
\[
B_i \cap B_j = (B \cap A_i) \cap (B \cap A_j) = B \cap (A_i \cap A_j) = B \cap \emptyset =\emptyset,
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\bigcup_i B_i = \bigcup_i \left(A_i \cap B\right )  = B \cap \left( \bigcup_i A_i \right) = B \cap S = B.
\]</div>
<p>These two properties imply that <span class="math notranslate nohighlight">\(B_0, B_1, \ldots, B_{n-1}\)</span> are a partition for <span class="math notranslate nohighlight">\(B\)</span>. If we want to express the probability of <span class="math notranslate nohighlight">\(B\)</span>, we can write</p>
<div class="amsmath math notranslate nohighlight" id="equation-5d167c04-ff5c-4f15-b538-67cb031d5a86">
<span class="eqno">(6.14)<a class="headerlink" href="#equation-5d167c04-ff5c-4f15-b538-67cb031d5a86" title="Permalink to this equation">¶</a></span>\[\begin{align}
P(B) &amp; = P \left( \bigcup_i B_i \right) \\
&amp; = \sum_i P \left(B_i \right) \\
&amp;= \sum_i P\left( B \cap A_i\right)
\end{align}\]</div>
<p>Now suppose that we choose the partitioning events <span class="math notranslate nohighlight">\(\{A_i\}\)</span> such that:</p>
<ul class="simple">
<li><p>We know the probabilities <span class="math notranslate nohighlight">\(P(A_i)\)</span></p></li>
<li><p>We know the conditional probabilities of the event <span class="math notranslate nohighlight">\(B\)</span> given that <span class="math notranslate nohighlight">\(A_i\)</span> occurred, <span class="math notranslate nohighlight">\(P(B|A_i)\)</span>.</p></li>
</ul>
<p>Applying chain rule, we can write <span class="math notranslate nohighlight">\(P(B \cap A_i) = P(B|A_i)P(A_i)\)</span> for each <span class="math notranslate nohighlight">\(i\)</span>. Putting this all together, we get the <em>Law of Total Probability</em>:</p>
<div class="sphinx-bs container pb-4 docutils">
<div class="row docutils">
<div class="d-flex col-lg-6 col-md-6 col-sm-6 col-xs-12 p-2 docutils">
<div class="card w-100 shadow docutils">
<div class="card-header docutils">
<p class="card-text">Law of Total Probability</p>
</div>
<div class="card-body docutils">
<p class="card-text">Given an event <span class="math notranslate nohighlight">\(B \subseteq S\)</span> and a partition of <span class="math notranslate nohighlight">\(S\)</span> denoted by
<span class="math notranslate nohighlight">\(A_1, A_2, \ldots\)</span>,</p>
<div class="math notranslate nohighlight">
\[
P(B) = \sum_i P(B|A_i)P(A_i).
\]</div>
</div>
</div>
</div>
</div>
</div>
<p>The law of total probability is often used in systems where there is either:</p>
<ul class="simple">
<li><p>random inputs and outputs, where the output is dependent on the input</p></li>
<li><p>a <em>hidden state</em>, which is some random property of the system that is not directly observable.</p></li>
</ul>
<p>Note that these are not mutually exclusive. For the Magician’s coin, we can treat the choice of coin as the input to the system or as a hidden state. When the coin is flipped repeatedly, then it generally makes more sense to interpret the choice of coin as a hidden state because it is a property of the system that cannot be directly observed but that influences the outpus of the system.</p>
<p>When applying chain rule in such problems, the Law of Total Probability will generally use conditioning on
the different possibilities of the input or the hidden state.</p>
<p><strong>Example: The Magician’s Coin</strong></p>
<p>As before, a magician has a fair coin and a two-headed coin in her pocket. Let <span class="math notranslate nohighlight">\(H_i\)</span> denote the event that the outcome of flip <span class="math notranslate nohighlight">\(i\)</span> is heads. We can use total probability to answer more complicated questions regarding the probabilities of the outputs:</p>
<p><strong>(a)</strong> <span class="math notranslate nohighlight">\(P(H_1)\)</span></p>
<p>As mentioned above, we can condition on the hidden state, which is whether the coin is fair (<span class="math notranslate nohighlight">\(F\)</span>) or not (<span class="math notranslate nohighlight">\(\overline{F}\)</span>).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>One thing that is often confusing to learners of probability is determining what is actually a partition of <span class="math notranslate nohighlight">\(S\)</span>.  If you have a set of events that are both <em>mutually exclusive</em> and <em>one of those events must occur</em> (i.e., the events cover the sample space), then they are a partition.</p>
<p>In this case, <span class="math notranslate nohighlight">\(F\)</span> and <span class="math notranslate nohighlight">\(\overline{F}\)</span> are complements, so they are mutually exclusive. Moreover, either the coin is fair (<span class="math notranslate nohighlight">\(F\)</span>) or it is not (<span class="math notranslate nohighlight">\(\overline{F}\)</span>), so one of these events must occur. Therefore the events <span class="math notranslate nohighlight">\(F, \overline{F}\)</span> partition <span class="math notranslate nohighlight">\(S\)</span>.</p>
</div>
<p>Applying the Law of Total Probability,</p>
<div class="amsmath math notranslate nohighlight" id="equation-efe291ea-e655-49e6-bc85-2c786a8eafce">
<span class="eqno">(6.15)<a class="headerlink" href="#equation-efe291ea-e655-49e6-bc85-2c786a8eafce" title="Permalink to this equation">¶</a></span>\[\begin{align}
P(H_1) &amp;= P(H_1|F)P(F) + P(H_1| \overline{F}) P( \overline{F}) \\
&amp;= \left( \frac 1 2 \right) \left( \frac 1 2 \right) + \biggl( 1\biggr) \left( \frac 1 2 \right) \\
&amp;= \frac 3 4
\end{align}\]</div>
<p><strong>(b)</strong> <span class="math notranslate nohighlight">\(P(H_1 \cap H_2)\)</span></p>
<p>We can use the same partition as above to write:</p>
<div class="amsmath math notranslate nohighlight" id="equation-a461f98f-1e48-4a61-bf40-8d6d087e8d0c">
<span class="eqno">(6.16)<a class="headerlink" href="#equation-a461f98f-1e48-4a61-bf40-8d6d087e8d0c" title="Permalink to this equation">¶</a></span>\[\begin{align}
P(H_1 \cap H_2) &amp;= P(H_1 \cap H_2 |F)P(F) + P(H_1\cap H_2| \overline{F}) P( \overline{F}).
\end{align}\]</div>
<p>However, now we need to know the probabilities <span class="math notranslate nohighlight">\(P(H_1 \cap H_2 |F)\)</span> and <span class="math notranslate nohighlight">\(P(H_1\cap H_2| \overline{F})\)</span>. When the coin is fair the events <span class="math notranslate nohighlight">\(H_1\)</span> and <span class="math notranslate nohighlight">\(H_2\)</span> are conditionally independent, so <span class="math notranslate nohighlight">\(P(H_1 \cap H_2 |F) =
P(H_1|F)P(H_2|F)\)</span>. When the coin is two-headed, it always comes up heads, so <span class="math notranslate nohighlight">\(P(H_1\cap H_2| \overline{F})=1\)</span>. Then</p>
<div class="amsmath math notranslate nohighlight" id="equation-bf18432a-666f-4b8d-91e9-12cd8efc1b91">
<span class="eqno">(6.17)<a class="headerlink" href="#equation-bf18432a-666f-4b8d-91e9-12cd8efc1b91" title="Permalink to this equation">¶</a></span>\[\begin{align}
P(H_1 \cap H_2) &amp;= P(H_1|F)P( H_2 |F)P(F) + (1) P( \overline{F}) \\
&amp;= \left( \frac 1 2 \right) \left( \frac 1 2 \right) \left( \frac 1 2 \right)
+\biggl( 1\biggr) \left( \frac 1 2 \right) \\
&amp;= \frac 5 8.
\end{align}\]</div>
<p><strong>(c)</strong> <span class="math notranslate nohighlight">\(P(H_2 \vert H_1)\)</span></p>
<p>By calculating this probability, we can assess whether getting heads on flip 2 is independent of getting heads on flip 1, and if now, how information about the value of the first flip changes the probabilities for the second flip.  We can directly apply the definition of conditional probability to calculate this from the answers to parts (a) and (b):</p>
<div class="math notranslate nohighlight">
\[
P(H_2 \vert H_1) = \frac{ P(H_1 \cap H_2) } {P(H_1)} = \frac{5/8}{3/4} = \frac{5}{6}
\]</div>
<p>If we did not know <span class="math notranslate nohighlight">\(H_1\)</span>, then <span class="math notranslate nohighlight">\(P(H_2)= P(H_1)=3/4\)</span> (you should verify this using the Law of Total Probability with <span class="math notranslate nohighlight">\(H_1\)</span> as the hidden state). So knowing that heads occurred on the first flip increases the probability that heads will occur on the second flip.</p>
<p>If this surprises you (again), then just recall that we can anticipate this if we take it to extremes. What if I told you that heads occurred on the first 1000 flips? Then you would surely think that the magician had chosen the two-headed coin and expect the probability of getting heads on the 1001th flip to be close to 1. Then if heads is  observed on one flip, we should expect the probability of getting heads on second flip to increase.</p>
<p>In fact, after observing one heads, the probability of having chosen the two-headed coin should increase to more than 1/2. It does – but we will need some new tools that we will develop in Chapter 7 before we can calculate the new probability.</p>
<p><strong>TO DO: Create numerical answer questions for</strong> <span class="math notranslate nohighlight">\(P(H_1 \cap H_2 \cap H_3)\)</span>,  <span class="math notranslate nohighlight">\(P(H_3 \vert H_1 \cap H_2)\)</span></p>
<p><strong>Example: Two Random Selections</strong></p>
<p>At the beginning of this Chapter, the following question was asked: A box contains 2 white balls and 1 black ball. I reach in the box and remove one ball. Without inspecting it, I place it in my pocket. I withdraw a second ball. What is the probability that the second ball is white?</p>
<p>This is a question that stumps many learners of probability, but the answer turns out to be simple. Let <span class="math notranslate nohighlight">\(W_i\)</span> be the event that a white ball is chosen on draw <span class="math notranslate nohighlight">\(i\)</span>. We are asking about <span class="math notranslate nohighlight">\(W_2\)</span>. Then <span class="math notranslate nohighlight">\(P(W_2) = P(W_1) = 2/3\)</span>.  However, this is not intuitive because our brain tells us that the probabilities for the second draw must depend on what happened on the first draw – which is unknown in this case.</p>
<p>We can formally show this using the Law of Total Probability. The conditioning event will be the unobserved result of the first draw. The partition is <span class="math notranslate nohighlight">\(W_1\)</span>, <span class="math notranslate nohighlight">\(\overline{W_1}\)</span>. Then</p>
<div class="amsmath math notranslate nohighlight" id="equation-e2eb2078-d704-4cb5-9736-59938f2a3862">
<span class="eqno">(6.18)<a class="headerlink" href="#equation-e2eb2078-d704-4cb5-9736-59938f2a3862" title="Permalink to this equation">¶</a></span>\[\begin{align}
P(W_2) &amp;= P(W_2|W_1) P(W_1) + P(W_2 | \overline{W_1}) P(\overline{W_1})\\
\end{align}\]</div>
<p>If a white ball is drawn first (<span class="math notranslate nohighlight">\(W_1\)</span>), then there is one white ball and one black ball left, so <span class="math notranslate nohighlight">\(P(W_2|W_1) = 1/2\)</span>. If a black ball is drawn first (<span class="math notranslate nohighlight">\(\overline{W_1}\)</span>), then there are two white balls left, so <span class="math notranslate nohighlight">\(P(W_1| 
\overline{W_1}) = 1\)</span>.  Then</p>
<div class="amsmath math notranslate nohighlight" id="equation-3f114fde-e824-4137-85f5-124ed228fd91">
<span class="eqno">(6.19)<a class="headerlink" href="#equation-3f114fde-e824-4137-85f5-124ed228fd91" title="Permalink to this equation">¶</a></span>\[\begin{align}
P(W_2) &amp;= \left( \frac 1 2 \right) \left( \frac 2 3 \right) + \biggl( 1 \biggr) 
\left( \frac 1 3 \right) \\
&amp;= \frac 2 3,
\end{align}\]</div>
<p>which is equal to <span class="math notranslate nohighlight">\(P(W_1)\)</span>.  We can use similar math to show that <span class="math notranslate nohighlight">\(P(W_3)=2/3\)</span>, also. In the absence of information about what happened on previous draws, the probability of getting a white ball is equal to the original proportion of white balls in the box.</p>
<p><strong>Example: The Monty Hall Problem</strong></p>
<p>You are on a game show, and you’re given the choice of three doors:</p>
<ul class="simple">
<li><p>Behind one door is a car</p></li>
<li><p>Behind the other doors are goats</p></li>
</ul>
<p>You pick a door, and the host, who knows what’s behind the doors, opens another door, which he knows has a goat.</p>
<p>The host then offers you the option to switch doors. Does it matter if you switch? If switching changes your probability of getting the prize, what is the new probability?</p>
<p>Here is a simple solution. Let <span class="math notranslate nohighlight">\(W_i\)</span> be the event that you are winning on choice <span class="math notranslate nohighlight">\(i\)</span>. Let <span class="math notranslate nohighlight">\(S\)</span> be the event that you switch. We are interested in comparing <span class="math notranslate nohighlight">\(P(W_2|S)\)</span> with <span class="math notranslate nohighlight">\(P(W_2 | \overline{S})\)</span>.</p>
<p>Consider <span class="math notranslate nohighlight">\(\overline{S}\)</span> first. Because there are two goats and the host always shows you a goat, the fact that he reveals a goat to you does not change the probability that you have selected the car. Thus <span class="math notranslate nohighlight">\(P(W_2|\overline{S}) = P(W_1) = 1/3\)</span>.</p>
<p>Now consider <span class="math notranslate nohighlight">\(S\)</span>.  It may be tempting to think that either:</p>
<ol class="simple">
<li><p>Switching doesn’t matter because the host was always going to show you a goat, so your new choice is just as likely to be a car as it was before, or</p></li>
<li><p>After the host reveals a goat, there is one goat and one car, so the probability of choosing the car when you switch is 1/2.</p></li>
</ol>
<p>Unfortunately, neither of these are correct! Let’s condition on what happens on choice 1:</p>
<div class="math notranslate nohighlight">
\[
P(W_2|S) = P(W_2|S \cap W_1) P(W_1|S) + P(W_2|S \cap \overline{W_1} ) P(\overline{W_1}|S).
\]</div>
<p>The probability of winning on choice 1 does not depend on whether you switch after that choice, so <span class="math notranslate nohighlight">\(P(W_1|S) = P(W_1) = 1/3\)</span>, and $P(\overline{W_1}|S) = P(\overline{W_1})= 2/3.</p>
<p>Now, consider what happens on the second choice. There are two possibilities:</p>
<ul class="simple">
<li><p>If you are winning on the first choice (<span class="math notranslate nohighlight">\(W_1\)</span>), then the two doors you have not chosen both contain goats. The host reveals one of the goats, and you will switch to the other goat. Thus, <span class="math notranslate nohighlight">\(P(W_2|W_1) =0\)</span>.</p></li>
<li><p>If you are not winning on the first choice (<span class="math notranslate nohighlight">\(\overline{W_1}\)</span>), then one of the doors you have not chosen has a goat and the other has the car. The host shows the goat that is not behind your door. Then if you switch, you will switch to the door with the car. Thus, <span class="math notranslate nohighlight">\(P(W_1 | \overline{W_1}) = 1\)</span>.</p></li>
</ul>
<p>Putting this all together,</p>
<div class="amsmath math notranslate nohighlight" id="equation-c0285f72-f1a5-4b17-9ab5-763b03212b3f">
<span class="eqno">(6.20)<a class="headerlink" href="#equation-c0285f72-f1a5-4b17-9ab5-763b03212b3f" title="Permalink to this equation">¶</a></span>\[\begin{align}
P(W_2|S) &amp;= P(W_2|S \cap W_1) P(W_1|S) + P(W_2|S \cap \overline{W_1} ) P(\overline{W_1}|S) \\
&amp;= \biggl( 0 \biggr) \left( \frac 1 3 \right) 
+ \biggl( 1 \biggr) \left( \frac 2 3 \right) \\
&amp;= \frac 2 3.
\end{align}\]</div>
<p>Why is the probability not 1/2 using the reasoning above about one car and one goat left? Because you do not randomly choose among the two doors. The host is revealing information when he reveals the goat because he cannot choose your door, and he cannot choose the door with the car. If you were to randomly choose between the two doors after the goat is revealed, the probability would be 1/2.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./06-conditional-prob"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="conditional-independence.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">6.8. </span>Conditioning and (In)dependence</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="review.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6.10. </span>Review</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By John M. Shea<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>